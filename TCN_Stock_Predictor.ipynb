{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Temporal Convolutional Network for Daytrading\n",
    "## Daniel Kalam, Sharvita Paithankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv1D, Dropout, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import pandas as pd\n",
    "from pandas_datareader import DataReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Getting data for 100 stocks in the date range of April 2nd, 2018 to October 9th, 2020 from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 25,
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
   "execution_count": 126,
>>>>>>> parent of 28bc195... Trainable TCN
=======
   "execution_count": 126,
>>>>>>> parent of 28bc195... Trainable TCN
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'TSLA', 'FB', 'GE', 'BRK', 'GOOGL', 'INTC', 'AMD', 'HPE', 'ZM',\n",
    "          'CAKE', 'AET', 'F', 'KO', 'DDS', 'NVDA', 'NFLX', 'JPM', 'AMZN', 'MSFT']\n",
    "#TODO: Add 80 more symbols.\n",
    "source = 'yahoo'\n",
    "start_date = pd.to_datetime('2018-02-04')\n",
    "end_date = pd.to_datetime('2020-10-09')\n",
    "stock_data = {}\n",
    "for symbol in symbols:\n",
    "    stock_data[symbol] = DataReader(symbol, source, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame for each column in a stock's data frame."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_training_data_input = np.empty((20, 676, 1))\n",
    "stock_training_data_output = np.zeros((20, 676, 2))\n",
    "i = 0\n",
    "scaler = StandardScaler()\n",
    "for symbol in stock_data:\n",
    "    close_data = stock_data[symbol].Close\n",
    "    open_data = stock_data[symbol].Open\n",
    "    stock_data[symbol].drop(axis= 1, columns = ['Close'], inplace = True)\n",
    "    stock_np = stock_data[symbol].to_numpy()\n",
    "    stock_np = scaler.fit_transform(stock_np)\n",
    "    if stock_np.shape == stock_training_data_input[i].shape:\n",
    "        stock_training_data_input[i, :, 0] = stock_np[:, 2]\n",
    "        for j in range(0, len(close_data[symbol])):\n",
    "            if close_data[j] > open_data[j]:\n",
    "                stock_training_data_output[i, j, 0] = 1\n",
    "                stock_training_data_output[i, j, 1] = 0\n",
    "            else:\n",
    "                stock_training_data_output[i, j, 0] = 0\n",
    "                stock_training_data_output[i, j, 1] = 1\n",
    "        i+=1"
=======
   "execution_count": 26,
=======
   "execution_count": 127,
>>>>>>> parent of 28bc195... Trainable TCN
=======
   "execution_count": 127,
>>>>>>> parent of 28bc195... Trainable TCN
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_training_data_input = np.empty((20, 676, 5))\n",
    "stock_training_data_output = np.zeros((20, 676, 2))\n",
    "i = 0\n",
    "scaler = StandardScaler()\n",
    "for symbol in stock_data:\n",
    "    close_data[symbol] = stock_data[symbol].Close\n",
    "    open_data[symbol] = stock_data[symbol].Open\n",
    "    stock_data[symbol].drop(axis= 1, columns = ['Close'], inplace = True)\n",
    "    stock_np = stock_data[symbol].to_numpy()\n",
    "    stock_np = scaler.fit_transform(stock_np)\n",
<<<<<<< HEAD
<<<<<<< HEAD
    "    #if stock_np.shape == stock_training_data_input[i].shape:\n",
    "    stock_training_input[i, :, :] = stock_np[:, :]\n",
    "    for j in range(0, len(close_data)):\n",
    "        if close_data[j] > open_data[j]:\n",
    "            stock_training_output[i, j, 0] = 1\n",
    "            stock_training_output[i, j, 1] = 0\n",
    "        else:\n",
    "            stock_training_output[i, j, 0] = 0\n",
    "            stock_training_output[i, j, 1] = 1\n",
    "    i+=1\n",
    "for symbol in stock_data_validation:\n",
    "    close_data = stock_data_validation[symbol].Close\n",
    "    open_data = stock_data_validation[symbol].Open\n",
    "    #stock_data[symbol].drop(axis= 1, columns = ['Close', 'High', 'Low', 'Volume', 'Adj Close'], inplace = True)\n",
    "    stock_np = stock_data_validation[symbol].Open.to_numpy().reshape(254, 1)\n",
    "    stock_np = scaler.fit_transform(stock_np)\n",
    "    #if stock_np.shape == stock_training_data_input[i].shape:\n",
    "    stock_validation_input[i, :, :] = stock_np[:, :]\n",
    "    for j in range(0, len(close_data)):\n",
    "        if close_data[j] > open_data[j]:\n",
    "            stock_validation_output[i, j, 0] = 1\n",
    "            stock_validation_output[i, j, 1] = 0\n",
    "        else:\n",
    "            stock_validation_output[i, j, 0] = 0\n",
    "            stock_validation_output[i, j, 1] = 1\n",
    "    i+=1"
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
=======
>>>>>>> parent of 28bc195... Trainable TCN
    "    if stock_np.shape == stock_training_data[i].shape:\n",
    "        stock_training_data_input[i, :, :] = stock_np[:, :]\n",
    "        for j in range(0, len(close_data[symbol])):\n",
    "            if close_data[symbol][j] > open_data[symbol][j]:\n",
    "                stock_training_data_output[i, j, 0] = 1\n",
    "                stock_training_data_output[i, j, 1] = 0\n",
    "            else:\n",
    "                stock_training_data_output[i, j, 0] = 0\n",
    "                stock_training_data_output[i, j, 1] = 1\n",
    "        i+=1"
<<<<<<< HEAD
>>>>>>> parent of 28bc195... Trainable TCN
=======
>>>>>>> parent of 28bc195... Trainable TCN
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "### Converting the Data Into Tensors\n",
    "Turn the data frames into tensorflow datatypes so that they can be processed by tensorflow."
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Date\n",
      "2018-02-05    39.775002\n",
      "2018-02-06    38.707500\n",
      "2018-02-07    40.772499\n",
      "2018-02-08    40.072498\n",
      "2018-02-09    39.267502\n",
      "2018-02-12    39.625000\n",
      "2018-02-13    40.487499\n",
      "2018-02-14    40.759998\n",
      "2018-02-15    42.447498\n",
      "2018-02-16    43.090000\n",
      "Name: Open, dtype: float64\n",
      "Date\n",
      "2018-02-05    39.122501\n",
      "2018-02-06    40.757500\n",
      "2018-02-07    39.884998\n",
      "2018-02-08    38.787498\n",
      "2018-02-09    39.102501\n",
      "2018-02-12    40.677502\n",
      "2018-02-13    41.084999\n",
      "2018-02-14    41.842499\n",
      "2018-02-15    43.247501\n",
      "2018-02-16    43.107498\n",
      "Name: Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(stock_training_data_output[0, :10, :])\n",
    "print(stock_data['AAPL'].Open[:10])\n",
    "print(close_data['AAPL'][:10])\n",
    "#feature_train = tf.convert_to_tensor(np.array((10, 637, 1)))\n",
    "#for i in range(0, 10):\n",
    "#    key = list(open_data.keys())[i]\n",
    "#    feature_train[i, :, :] = tf.convert_to_tensor(np.array(stock_training_data[key]).reshape(len(open_data[key]), 5))\n",
    "#open_aapl = open_data['AAPL']\n",
    "#open_aapl = open_aapl[0 : 637]\n",
    "#open_aapl = np.array(open_aapl).reshape(1, 637, 1)\n",
    "#open_aapl_train = tf.convert_to_tensor(open_aapl)\n",
    "#close_aapl = close_data['AAPL']\n",
    "#close_aapl = close_aapl[0 : 637]\n",
    "#close_aapl = np.array(close_aapl).reshape(1, 637, 1)"
   ]
  },
  {
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network Class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 28,
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
   "execution_count": 129,
>>>>>>> parent of 28bc195... Trainable TCN
=======
   "execution_count": 129,
>>>>>>> parent of 28bc195... Trainable TCN
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_count = 5 # Amount of filters\n",
    "final_filter_count = 2\n",
    "filters = [] # Filter size for each residual block\n",
    "kernel_size = 10 #Resolution of each filter\n",
    "level = kernel_size\n",
    "n = 0\n",
    "while level <= 676:\n",
    "    filters.append(filter_count)\n",
    "    level+=kernel_size + (kernel_size-1)*2**n\n",
    "    n+=1\n",
    "filters[-1] = final_filter_count"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 29,
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
   "execution_count": 130,
>>>>>>> parent of 28bc195... Trainable TCN
=======
   "execution_count": 130,
>>>>>>> parent of 28bc195... Trainable TCN
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, dilation_rate, activation,\n",
    "                trainable, dropout, dtype=None, activity_regularizer=None, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(trainable, dtype=dtype)\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.filters = filters\n",
    "        self.adjust_sample = None\n",
    "        self.layer_norm = BatchNormalization(axis=-1)\n",
    "        self.dilatedcausal1 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "        self.dilatedcausal2 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "\n",
    "    #Make the dropout based on the shape of the input\n",
    "    def build(self, input_shape):\n",
    "        self.drop1 = Dropout(self.dropout, input_shape)\n",
    "        self.drop2 = Dropout(self.dropout, input_shape)\n",
    "        if input_shape[2]!=filters:\n",
    "            self.adjust_sample = Dense(self.filters)\n",
    "\n",
    "    #The residual block processes the input\n",
    "    def call(self, inputs, training):\n",
    "        x = self.dilatedcausal1(inputs)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop1(x, training) #If training is False, drop1 simply returns x\n",
    "        x = self.dilatedcausal2(x)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop2(x, training) #If training is False, drop2 simply returns x\n",
    "        if self.adjust_sample is not None:\n",
    "            inputs = self.adjust_sample(inputs)\n",
    "        return self.activation(x+inputs)\n",
    "        \n",
    "class TCN(Model):\n",
    "    def __init__(self, filters, kernel_size=2, dropout = 0.2, activation='relu',\n",
    "                trainable=False, dtype=None, name=None,\n",
    "                activity_regularizer=None, **kwargs):\n",
    "        super(TCN, self).__init__()\n",
    "        self.levels = []\n",
    "        for i in range(0, len(filters)):\n",
    "            self.levels.append(ResidualBlock(filters[i], kernel_size,\n",
    "                                             1, 2**i, Activation(activation),\n",
    "                                             trainable, dropout,\n",
    "                                             dtype, activity_regularizer))\n",
    "    \n",
    "    #Running the input through each residual block\n",
    "    def call(self, inputs, training=False):\n",
    "        for r_block in self.levels:\n",
    "            inputs = r_block(inputs, training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 31,
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
   "execution_count": 134,
>>>>>>> parent of 28bc195... Trainable TCN
=======
   "execution_count": 134,
>>>>>>> parent of 28bc195... Trainable TCN
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
     "ename": "StagingError",
     "evalue": "in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-5-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-5-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n",
=======
     "ename": "StagingError",
     "evalue": "in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-91-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-130-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n",
>>>>>>> parent of 28bc195... Trainable TCN
=======
     "ename": "StagingError",
     "evalue": "in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-91-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-130-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n",
>>>>>>> parent of 28bc195... Trainable TCN
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStagingError\u001b[0m                              Traceback (most recent call last)",
<<<<<<< HEAD
<<<<<<< HEAD
      "\u001b[1;32m<ipython-input-6-5b283288aeb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtcn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
=======
      "\u001b[1;32m<ipython-input-134-5b283288aeb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtcn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
>>>>>>> parent of 28bc195... Trainable TCN
=======
      "\u001b[1;32m<ipython-input-134-5b283288aeb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtcn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstock_training_data_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
>>>>>>> parent of 28bc195... Trainable TCN
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
<<<<<<< HEAD
<<<<<<< HEAD
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-5-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-5-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4747 - accuracy: 0.3770 - val_loss: 0.0056 - val_accuracy: 0.2918\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4319 - accuracy: 0.3814 - val_loss: 0.0055 - val_accuracy: 0.2928\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4123 - accuracy: 0.3893 - val_loss: 0.0054 - val_accuracy: 0.2938\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4200 - accuracy: 0.4070 - val_loss: 0.0053 - val_accuracy: 0.2948\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3894 - accuracy: 0.4154 - val_loss: 0.0052 - val_accuracy: 0.2963\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4066 - accuracy: 0.4281 - val_loss: 0.0051 - val_accuracy: 0.2982\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3751 - accuracy: 0.3917 - val_loss: 0.0051 - val_accuracy: 0.2987\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3623 - accuracy: 0.4193 - val_loss: 0.0050 - val_accuracy: 0.3017\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3570 - accuracy: 0.4163 - val_loss: 0.0049 - val_accuracy: 0.3027\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3597 - accuracy: 0.4277 - val_loss: 0.0048 - val_accuracy: 0.3041\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3717 - accuracy: 0.3745 - val_loss: 0.0048 - val_accuracy: 0.3061\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3682 - accuracy: 0.4085 - val_loss: 0.0047 - val_accuracy: 0.3066\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3109 - accuracy: 0.4577 - val_loss: 0.0046 - val_accuracy: 0.3115\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3312 - accuracy: 0.4129 - val_loss: 0.0045 - val_accuracy: 0.3130\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2993 - accuracy: 0.4001 - val_loss: 0.0044 - val_accuracy: 0.3155\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3012 - accuracy: 0.3971 - val_loss: 0.0044 - val_accuracy: 0.3189\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2931 - accuracy: 0.3981 - val_loss: 0.0043 - val_accuracy: 0.3204\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2676 - accuracy: 0.4473 - val_loss: 0.0042 - val_accuracy: 0.3233\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2827 - accuracy: 0.4193 - val_loss: 0.0042 - val_accuracy: 0.4232\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2738 - accuracy: 0.4562 - val_loss: 0.0041 - val_accuracy: 0.4272\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3120 - accuracy: 0.3755 - val_loss: 0.0041 - val_accuracy: 0.4286\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2851 - accuracy: 0.4321 - val_loss: 0.0040 - val_accuracy: 0.4331\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2790 - accuracy: 0.4523 - val_loss: 0.0039 - val_accuracy: 0.4360\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2712 - accuracy: 0.4311 - val_loss: 0.0038 - val_accuracy: 0.4847\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2532 - accuracy: 0.3912 - val_loss: 0.0037 - val_accuracy: 0.4872\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2373 - accuracy: 0.4409 - val_loss: 0.0036 - val_accuracy: 0.4916\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2708 - accuracy: 0.4242 - val_loss: 0.0036 - val_accuracy: 0.4941\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2310 - accuracy: 0.4473 - val_loss: 0.0035 - val_accuracy: 0.4985\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2331 - accuracy: 0.4528 - val_loss: 0.0034 - val_accuracy: 0.5000\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2088 - accuracy: 0.4651 - val_loss: 0.0033 - val_accuracy: 0.5039\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2142 - accuracy: 0.4144 - val_loss: 0.0032 - val_accuracy: 0.5064\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2385 - accuracy: 0.4572 - val_loss: 0.0032 - val_accuracy: 0.5074\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1852 - accuracy: 0.4444 - val_loss: 0.0031 - val_accuracy: 0.5089\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2127 - accuracy: 0.4739 - val_loss: 0.0030 - val_accuracy: 0.5118\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1914 - accuracy: 0.4990 - val_loss: 0.0029 - val_accuracy: 0.5153\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1919 - accuracy: 0.4897 - val_loss: 0.0029 - val_accuracy: 0.5167\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2014 - accuracy: 0.4454 - val_loss: 0.0028 - val_accuracy: 0.5167\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2028 - accuracy: 0.4690 - val_loss: 0.0027 - val_accuracy: 0.5182\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1762 - accuracy: 0.4715 - val_loss: 0.0027 - val_accuracy: 0.5197\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1856 - accuracy: 0.4582 - val_loss: 0.0026 - val_accuracy: 0.5236\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1772 - accuracy: 0.4454 - val_loss: 0.0025 - val_accuracy: 0.5251\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1833 - accuracy: 0.4719 - val_loss: 0.0025 - val_accuracy: 0.5266\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1900 - accuracy: 0.5079 - val_loss: 0.0024 - val_accuracy: 0.5290\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1700 - accuracy: 0.4537 - val_loss: 0.0023 - val_accuracy: 0.5763\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1553 - accuracy: 0.4547 - val_loss: 0.0023 - val_accuracy: 0.5782\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1778 - accuracy: 0.4808 - val_loss: 0.0022 - val_accuracy: 0.5787\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1732 - accuracy: 0.5281 - val_loss: 0.0021 - val_accuracy: 0.5802\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1576 - accuracy: 0.4872 - val_loss: 0.0020 - val_accuracy: 0.5812\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1504 - accuracy: 0.4921 - val_loss: 0.0020 - val_accuracy: 0.5822\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1602 - accuracy: 0.5020 - val_loss: 0.0019 - val_accuracy: 0.5832\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1380 - accuracy: 0.4916 - val_loss: 0.0019 - val_accuracy: 0.5842\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1185 - accuracy: 0.4882 - val_loss: 0.0018 - val_accuracy: 0.5851\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1400 - accuracy: 0.5192 - val_loss: 0.0017 - val_accuracy: 0.5876\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1265 - accuracy: 0.5084 - val_loss: 0.0017 - val_accuracy: 0.5906\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1365 - accuracy: 0.4877 - val_loss: 0.0016 - val_accuracy: 0.5915\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1216 - accuracy: 0.5408 - val_loss: 0.0016 - val_accuracy: 0.6545\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1379 - accuracy: 0.5384 - val_loss: 0.0015 - val_accuracy: 0.6550\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1015 - accuracy: 0.4877 - val_loss: 0.0015 - val_accuracy: 0.6565\n",
      "Epoch 117/250\n"
>>>>>>> 28bc195401627dceacb9a3e0a6518e8b30c146f8
=======
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-91-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-130-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n"
>>>>>>> parent of 28bc195... Trainable TCN
=======
      "\u001b[1;31mStagingError\u001b[0m: in user code:\n\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-91-bcebe246852f>:57 call  *\n        inputs = r_block(inputs, training)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:982 __call__  **\n        self._maybe_build(inputs)\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:2643 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    <ipython-input-130-bcebe246852f>:25 build\n        if input_shape[2]!=filters:\n    C:\\Users\\oneof\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:887 __getitem__\n        return self._dims[key].value\n\n    IndexError: list index out of range\n"
>>>>>>> parent of 28bc195... Trainable TCN
     ]
    }
   ],
   "source": [
    "tcn_model = TCN(filters, kernel_size, activation='relu', trainable = True, dtype='float')\n",
    "tcn_model.compile(optimizer='adam', loss = 'mse')\n",
    "tcn_model.fit(x=stock_training_data_input[0], y=stock_training_data_output[0], epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0/..;.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
