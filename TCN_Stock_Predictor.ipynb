{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Temporal Convolutional Network for Daytrading\n",
    "## Daniel Kalam, Sharvita Paithankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv1D, Dropout, Dense\n",
    "import pandas as pd\n",
    "from pandas_datareader import DataReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Getting data for 100 stocks in the date range of April 2nd, 2018 to October 9th, 2020 from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'TSLA', 'FB', 'GE', 'BRK', 'GOOGL', 'INTC', 'AMD', 'HPE', 'ZM',\n",
    "          'CAKE', 'AET', 'F', 'KO', 'DDS', 'NVDA', 'NFLX', 'JPM', 'AMZN', 'MSFT']\n",
    "#TODO: Add 80 more symbols.\n",
    "source = 'yahoo'\n",
    "start_date = pd.to_datetime('2018-02-04')\n",
    "end_date = pd.to_datetime('2020-10-09')\n",
    "stock_data = {}\n",
    "for symbol in symbols:\n",
    "    stock_data[symbol] = DataReader(symbol, source, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame for each column in a stock's data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_data = {}\n",
    "close_data = {}\n",
    "high_data = {}\n",
    "low_data = {}\n",
    "volume_data = {}\n",
    "adj_close_data = {}\n",
    "for symbol in stock_data:\n",
    "    open_data[symbol] = stock_data[symbol].Open\n",
    "    close_data[symbol] = stock_data[symbol].Close\n",
    "    high_data[symbol] = stock_data[symbol].High\n",
    "    low_data[symbol] = stock_data[symbol].Low\n",
    "    volume_data[symbol] = stock_data[symbol].Volume\n",
    "    adj_close_data[symbol] = stock_data[symbol]['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "### Converting the Data Into Tensors\n",
    "Turn the data frames into tensorflow datatypes so that they can be processed by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1a1db345cdef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mopen_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mopen_aapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AAPL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mopen_aapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen_aapl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m637\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "open_train = tf.convert_to_tensor(np.array((10, 637, 1)))\n",
    "for i in range(0, 10):\n",
    "    key = list(open_data.keys())[i]\n",
    "    print(key)\n",
    "    open_train[i] = tf.convert_to_tensor(np.array(open_data[key]).reshape(len(open_data[key]), 1))\n",
    "open_aapl = open_data['AAPL']\n",
    "open_aapl = open_aapl[0 : 637]\n",
    "open_aapl = np.array(open_aapl).reshape(1, 637, 1)\n",
    "open_aapl_train = tf.convert_to_tensor(open_aapl)\n",
    "close_aapl = close_data['AAPL']\n",
    "close_aapl = close_aapl[0 : 637]\n",
    "close_aapl = np.array(close_aapl).reshape(1, 637, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilated 1D Causal Convolutional Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dilated1DCausalConvolutionalNetwork(Conv1D):\n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=tf.zeros_initializer(),\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 trainable=True,\n",
    "                 name=None,\n",
    "                 **kwargs):\n",
    "        super(Dilated1DCausalConvolutionalNetwork, self).__init__(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding='valid',\n",
    "            data_format='channels_last',\n",
    "            dilation_rate=dilation_rate,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            bias_initializer=bias_initializer,\n",
    "            kernel_regularizer=kernel_regularizer,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            kernel_constraint=kernel_constraint,\n",
    "            bias_constraint=bias_constraint,\n",
    "            trainable=trainable,\n",
    "            name=name,\n",
    "            **kwargs\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        padding = (self.kernel_size[0] - 1)*self.dilation_rate[0]\n",
    "        inputs = tf.pad(inputs, tf.constant([(0, 0), (1, 0), (0, 0)])*padding)\n",
    "        return super(Dilated1DCausalConvolutionalNetwork, self).call(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Residual Block Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalResidualBlock(Layer):\n",
    "    def __init__(self, n_outputs, kernel_size, strides, dilation_rate, dropout = 0.2,\n",
    "                trainable=True, name=None, dtype=None, activity_regularizer=None, **kwargs):\n",
    "        super(TemporalResidualBlock, self).__init__(\n",
    "            trainable=trainable, name=name, dtype=dtype,\n",
    "            activity_regularizer=activity_regularizer, **kwargs\n",
    "        )\n",
    "        self.dropout = dropout\n",
    "        self.n_outputs = n_outputs\n",
    "        self.conv1 = Dilated1DCausalConvolutionalNetwork(n_outputs, kernel_size, strides=strides,\n",
    "                                                        dilation_rate=dilation_rate, activation=tf.nn.relu,\n",
    "                                                        name='conv1', trainable=trainable)\n",
    "        self.conv2 = Dilated1DCausalConvolutionalNetwork(n_outputs, kernel_size, strides=strides,\n",
    "                                                        dilation_rate=dilation_rate, activation=tf.nn.relu,\n",
    "                                                        name='conv2', trainable=trainable)\n",
    "        self.down_sample=None\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        channel_dim=2\n",
    "        self.dropout1 = Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        self.dropout2 = Dropout(self.dropout, [tf.constant(1), tf.constant(1), tf.constant(self.n_outputs)])\n",
    "        if input_shape[channel_dim] != self.n_outputs:\n",
    "            self.down_sample = Dense(self.n_outputs, activation=None)\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.keras.layers.layer_norm(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.keras.layers.layer_norm(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        if self.down_sample is not None:\n",
    "            inputs = self.down_sample(inputs)\n",
    "        return tf.nn.relu(x + inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvolutionalNetwork(Layer):\n",
    "    def __init__(self, num_channels, kernel_size=2, dropout = 0.2,\n",
    "                trainable=True, dtype=None, name=None,\n",
    "                activity_regularizer=None, **kwargs):\n",
    "        super(TemporalConvolutionalNetwork, self).__init__(\n",
    "            trainable=trainable, dtype=dtype, name=name,\n",
    "            activity_regularizer=activity_regularizer, **kwargs)\n",
    "        self.layers = []\n",
    "        for i in range(len(num_channels)):\n",
    "            dilation_size = 2**i\n",
    "            self.layers.append(TemporalResidualBlock(num_channels[i], kernel_size, strides=1, dilation_rate=dilation_size,\n",
    "                                     dropout=dropout, name='tblock_{}'.format(i), trainable=trainable))\n",
    "    def call(self, inputs, training=True):\n",
    "        outputs = inputs\n",
    "        for layer in self.layers:\n",
    "            outputs = layer(outputs, training=training)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_count = 20 # Amount of filters\n",
    "filters = [] # Filter size for each residual block\n",
    "kernel_size = 10 #Resolution of each filter\n",
    "level = kernel_size\n",
    "n = 0\n",
    "while level <= len(open_data0):\n",
    "    filters.append(filter_count)\n",
    "    level+=kernel_size + (kernel_size-1)*2**n\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_trading_tcn = TemporalConvolutionalNetwork(filters, kernel_size, dtype='float32')\n",
    "output = day_trading_tcn(open_aapl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_aapl = tf.convert_to_tensor(close_aapl)\n",
    "close_aapl_bool = [int(close_aapl[0, i, 0] > open_aapl_train[0, i, 0]) for i in range(len(close_aapl[0]))]\n",
    "pred_close_aapl_bool = [int(float(output[0, i, 0]) > open_aapl_train[0, i, 0]) for i in range(len(open_aapl_train[0]))]\n",
    "np.mean(close_aapl_bool == pred_close_aapl_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TemporalConvolutionalNetwork' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-2d9f8f04e191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mday_trading_tcn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'TemporalConvolutionalNetwork' object has no attribute 'fit'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
