{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Temporal Convolutional Network for Daytrading\n",
    "## Daniel Kalam, Sharvita Paithankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv1D, Dropout, Dense, Activation, BatchNormalization\n",
    "import pandas as pd\n",
    "from pandas_datareader import DataReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Getting data for 100 stocks in the date range of April 2nd, 2018 to October 9th, 2020 from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'TSLA', 'FB', 'GE', 'BRK', 'GOOGL', 'INTC', 'AMD', 'HPE', 'ZM',\n",
    "          'CAKE', 'AET', 'F', 'KO', 'DDS', 'NVDA', 'NFLX', 'JPM', 'AMZN', 'MSFT']\n",
    "#TODO: Add 80 more symbols.\n",
    "source = 'yahoo'\n",
    "start_date = pd.to_datetime('2018-02-04')\n",
    "end_date = pd.to_datetime('2020-10-09')\n",
    "stock_data = {}\n",
    "for symbol in symbols:\n",
    "    stock_data[symbol] = DataReader(symbol, source, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame for each column in a stock's data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_data = {}\n",
    "close_data = {}\n",
    "high_data = {}\n",
    "low_data = {}\n",
    "volume_data = {}\n",
    "adj_close_data = {}\n",
    "for symbol in stock_data:\n",
    "    open_data[symbol] = stock_data[symbol].Open\n",
    "    close_data[symbol] = stock_data[symbol].Close\n",
    "    high_data[symbol] = stock_data[symbol].High\n",
    "    low_data[symbol] = stock_data[symbol].Low\n",
    "    volume_data[symbol] = stock_data[symbol].Volume\n",
    "    adj_close_data[symbol] = stock_data[symbol]['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "### Converting the Data Into Tensors\n",
    "Turn the data frames into tensorflow datatypes so that they can be processed by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_train = tf.convert_to_tensor(np.array((10, 637, 1)))\n",
    "for i in range(0, 10):\n",
    "    key = list(open_data.keys())[i]\n",
    "    #open_train[i] = tf.convert_to_tensor(np.array(open_data[key]).reshape(len(open_data[key]), 1))\n",
    "open_aapl = open_data['AAPL']\n",
    "open_aapl = open_aapl[0 : 637]\n",
    "open_aapl = np.array(open_aapl).reshape(1, 637, 1)\n",
    "open_aapl_train = tf.convert_to_tensor(open_aapl)\n",
    "close_aapl = close_data['AAPL']\n",
    "close_aapl = close_aapl[0 : 637]\n",
    "close_aapl = np.array(close_aapl).reshape(1, 637, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_count = 20 # Amount of filters\n",
    "filters = [] # Filter size for each residual block\n",
    "kernel_size = 10 #Resolution of each filter\n",
    "level = kernel_size\n",
    "n = 0\n",
    "while level <= 637:\n",
    "    filters.append(filter_count)\n",
    "    level+=kernel_size + (kernel_size-1)*2**n\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, dilation_rate, activation,\n",
    "                trainable, dropout, dtype=None, activity_regularizer=None, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(trainable, dtype=dtype)\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.filters = filters\n",
    "        self.adjust_sample = None\n",
    "        self.layer_norm = BatchNormalization(axis=-1)\n",
    "        self.dilatedcausal1 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "        self.dilatedcausal2 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "\n",
    "    #Make the dropout based on the shape of the input\n",
    "    def build(self, input_shape):\n",
    "        self.drop1 = Dropout(self.dropout, input_shape)\n",
    "        self.drop2 = Dropout(self.dropout, input_shape)\n",
    "        if input_shape[2]!=filters:\n",
    "            self.adjust_sample = Dense(self.filters)\n",
    "\n",
    "    #The residual block processes the input\n",
    "    def call(self, inputs, training):\n",
    "        x = self.dilatedcausal1(inputs)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop1(x, training) #If training is False, drop1 simply returns x\n",
    "        x = self.dilatedcausal2(x)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop2(x, training) #If training is False, drop2 simply returns x\n",
    "        if self.adjust_sample is not None:\n",
    "            inputs = self.adjust_sample(inputs)\n",
    "        return self.activation(x+inputs)\n",
    "        \n",
    "class TCN(Model):\n",
    "    def __init__(self, filters, kernel_size=2, dropout = 0.2, activation='relu',\n",
    "                trainable=False, dtype=None, name=None,\n",
    "                activity_regularizer=None, **kwargs):\n",
    "        super(TCN, self).__init__()\n",
    "        self.levels = []\n",
    "        for i in range(0, len(filters)):\n",
    "            self.levels.append(ResidualBlock(filters[i], kernel_size,\n",
    "                                             1, 2**i, Activation(activation),\n",
    "                                             trainable, dropout,\n",
    "                                             dtype, activity_regularizer))\n",
    "    \n",
    "    #Running the input through each residual block\n",
    "    def call(self, inputs, training=False):\n",
    "        for r_block in self.levels:\n",
    "            inputs = r_block(inputs, training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.6073861  0.34409004 0.43042523 ... 0.49353698 0.39382455 0.8205135 ]\n",
      "  [0.60738635 0.34409022 0.43042496 ... 0.49353704 0.39382467 0.8205135 ]\n",
      "  [0.6073957  0.34409216 0.430414   ... 0.49353966 0.3938288  0.82051325]\n",
      "  ...\n",
      "  [0.586775   0.3139089  0.43800172 ... 0.4645725  0.41251302 0.83354807]\n",
      "  [0.586775   0.31390893 0.43800166 ... 0.46457243 0.41251305 0.83354807]\n",
      "  [0.58677495 0.31390882 0.43800163 ... 0.4645725  0.41251302 0.8335482 ]]], shape=(1, 637, 20), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tcn_model = TCN(filters, kernel_size, activation='sigmoid', trainable = True, dtype='float')\n",
    "output = tcn_model(tf.cast(open_aapl_train, tf.float32))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
