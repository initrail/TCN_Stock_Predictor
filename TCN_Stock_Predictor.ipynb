{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Temporal Convolutional Network for Daytrading\n",
    "## Daniel Kalam, Sharvita Paithankar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv1D, Dropout, Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import pandas as pd\n",
    "from pandas_datareader import DataReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data\n",
    "Getting data for 100 stocks in the date range of April 2nd, 2018 to October 9th, 2020 from yahoo finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'TSLA', 'FB', 'GE']# , 'BRK', 'GOOGL', 'INTC', 'AMD', 'HPE', 'ZM',\n",
    "          #'CAKE', 'AET', 'F', 'KO', 'DDS', 'NVDA', 'NFLX', 'JPM', 'AMZN', 'MSFT']\n",
    "#TODO: Add 80 more symbols.\n",
    "source = 'yahoo'\n",
    "start_date = pd.to_datetime('2019-10-09')\n",
    "end_date = pd.to_datetime('2020-10-09')\n",
    "stock_data_training = {}\n",
    "for symbol in symbols:\n",
    "    stock_data_training[symbol] = DataReader(symbol, source, start_date, end_date)\n",
    "symbols2 = ['NFLX', 'JPM', 'AMZN', 'MSFT']\n",
    "stock_data_validation = {}\n",
    "for symbol in symbols2:\n",
    "    stock_data_validation[symbol] = DataReader(symbol, source, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame for each column in a stock's data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_training_input = np.empty((20, 254, 1))\n",
    "stock_training_output = np.zeros((20, 254, 2))\n",
    "stock_validation_input = np.empty((20, 254, 1))\n",
    "stock_validation_output = np.zeros((20, 254, 2))\n",
    "i = 0\n",
    "scaler = StandardScaler()\n",
    "for symbol in stock_data_training:\n",
    "    close_data = stock_data_training[symbol].Close\n",
    "    open_data = stock_data_training[symbol].Open\n",
    "    #stock_data[symbol].drop(axis= 1, columns = ['Close', 'High', 'Low', 'Volume', 'Adj Close'], inplace = True)\n",
    "    stock_np = stock_data_training[symbol].Open.to_numpy().reshape(254, 1)\n",
    "    stock_np = scaler.fit_transform(stock_np)\n",
    "    #if stock_np.shape == stock_training_input[i].shape:\n",
    "    stock_training_input[i, :, :] = stock_np[:, :]\n",
    "    for j in range(0, len(close_data)):\n",
    "        if close_data[j] > open_data[j]:\n",
    "            stock_training_output[i, j, 0] = 1\n",
    "            stock_training_output[i, j, 1] = 0\n",
    "        else:\n",
    "            stock_training_output[i, j, 0] = 0\n",
    "            stock_training_output[i, j, 1] = 1\n",
    "    i+=1\n",
    "for symbol in stock_data_validation:\n",
    "    close_data = stock_data_validation[symbol].Close\n",
    "    open_data = stock_data_validation[symbol].Open\n",
    "    #stock_data[symbol].drop(axis= 1, columns = ['Close', 'High', 'Low', 'Volume', 'Adj Close'], inplace = True)\n",
    "    stock_np = stock_data_validation[symbol].Open.to_numpy().reshape(254, 1)\n",
    "    stock_np = scaler.fit_transform(stock_np)\n",
    "    #if stock_np.shape == stock_training_input[i].shape:\n",
    "    stock_validation_input[i, :, :] = stock_np[:, :]\n",
    "    for j in range(0, len(close_data)):\n",
    "        if close_data[j] > open_data[j]:\n",
    "            stock_validation_output[i, j, 0] = 1\n",
    "            stock_validation_output[i, j, 1] = 0\n",
    "        else:\n",
    "            stock_validation_output[i, j, 0] = 0\n",
    "            stock_validation_output[i, j, 1] = 1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "### Converting the Data Into Tensors\n",
    "Turn the data frames into tensorflow datatypes so that they can be processed by tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-dbceed9d368c>:7: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  stock_validation_input = np.delete(stock_training_input, delete, axis=0)\n",
      "<ipython-input-39-dbceed9d368c>:8: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  stock_validation_output = np.delete(stock_training_output, delete, axis=0)\n"
     ]
    }
   ],
   "source": [
    "delete = []\n",
    "for j in range(i, 20):\n",
    "    delete.append(j)\n",
    "stock_training_input = np.delete(stock_training_input, delete, axis=0)\n",
    "stock_training_output = np.delete(stock_training_output, delete, axis=0)\n",
    "\n",
    "stock_validation_input = np.delete(stock_training_input, delete, axis=0)\n",
    "stock_validation_output = np.delete(stock_training_output, delete, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_count = 2 # Amount of filters\n",
    "final_filter_count = 2\n",
    "filters = [] # Filter size for each residual block\n",
    "kernel_size = 10 #Resolution of each filter\n",
    "level = kernel_size\n",
    "n = 0\n",
    "while level <= 254:\n",
    "    filters.append(filter_count)\n",
    "    level+=kernel_size + (kernel_size-1)*2**n\n",
    "    n+=1\n",
    "filters[-1] = final_filter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, filters, kernel_size, strides, dilation_rate, activation,\n",
    "                trainable, dropout, dtype=None, activity_regularizer=None, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(trainable, dtype=dtype)\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.filters = filters\n",
    "        self.adjust_sample = None\n",
    "        self.layer_norm = BatchNormalization(axis=-1)\n",
    "        self.dilatedcausal1 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "        self.dilatedcausal2 = Conv1D(filters,\n",
    "                                     kernel_size,\n",
    "                                     strides,\n",
    "                                     'causal',\n",
    "                                     dilation_rate=dilation_rate)\n",
    "\n",
    "    #Make the dropout based on the shape of the input\n",
    "    def build(self, input_shape):\n",
    "        self.drop1 = Dropout(self.dropout, input_shape)\n",
    "        self.drop2 = Dropout(self.dropout, input_shape)\n",
    "        if input_shape[2]!=filters:\n",
    "            self.adjust_sample = Dense(self.filters)\n",
    "\n",
    "    #The residual block processes the input\n",
    "    def call(self, inputs, training):\n",
    "        x = self.dilatedcausal1(inputs)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop1(x, training) #If training is False, drop1 simply returns x\n",
    "        x = self.dilatedcausal2(x)\n",
    "        x = self.layer_norm(x, training)\n",
    "        x = self.activation(x)\n",
    "        x = self.drop2(x, training) #If training is False, drop2 simply returns x\n",
    "        if self.adjust_sample is not None:\n",
    "            inputs = self.adjust_sample(inputs)\n",
    "        return self.activation(x+inputs)\n",
    "        \n",
    "class TCN(Model):\n",
    "    def __init__(self, filters, kernel_size=2, dropout = 0.2, activation='relu',\n",
    "                trainable=False, dtype=None, name=None,\n",
    "                activity_regularizer=None, **kwargs):\n",
    "        super(TCN, self).__init__()\n",
    "        self.levels = []\n",
    "        for i in range(0, len(filters)):\n",
    "            self.levels.append(ResidualBlock(filters[i], kernel_size,\n",
    "                                             1, 2**i, Activation(activation),\n",
    "                                             trainable, dropout,\n",
    "                                             dtype, activity_regularizer))\n",
    "    \n",
    "    #Running the input through each residual block\n",
    "    def call(self, inputs, training=True):\n",
    "        for r_block in self.levels:\n",
    "            inputs = r_block(inputs, training)\n",
    "        return inputs\n",
    "stock_training_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2994 - accuracy: 0.5733 - val_loss: 0.2449 - val_accuracy: 0.6383\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.2813 - accuracy: 0.5679 - val_loss: 0.2434 - val_accuracy: 0.5915\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2068 - accuracy: 0.5832 - val_loss: 0.2416 - val_accuracy: 0.5586\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1516 - accuracy: 0.5842 - val_loss: 0.2399 - val_accuracy: 0.5359\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1450 - accuracy: 0.5758 - val_loss: 0.2386 - val_accuracy: 0.5217\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1717 - accuracy: 0.5792 - val_loss: 0.2373 - val_accuracy: 0.5236\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1282 - accuracy: 0.5733 - val_loss: 0.2363 - val_accuracy: 0.5281\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1123 - accuracy: 0.5787 - val_loss: 0.2351 - val_accuracy: 0.5364\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0994 - accuracy: 0.6014 - val_loss: 0.2343 - val_accuracy: 0.5448\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0632 - accuracy: 0.5817 - val_loss: 0.2335 - val_accuracy: 0.5561\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0579 - accuracy: 0.5999 - val_loss: 0.2327 - val_accuracy: 0.5684\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0675 - accuracy: 0.5591 - val_loss: 0.2320 - val_accuracy: 0.5768\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9553 - accuracy: 0.5886 - val_loss: 0.2314 - val_accuracy: 0.5758\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9252 - accuracy: 0.5792 - val_loss: 0.2308 - val_accuracy: 0.5846\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9876 - accuracy: 0.5753 - val_loss: 0.2300 - val_accuracy: 0.5886\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9738 - accuracy: 0.5866 - val_loss: 0.2294 - val_accuracy: 0.5915\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9320 - accuracy: 0.5906 - val_loss: 0.2287 - val_accuracy: 0.5930\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9130 - accuracy: 0.5950 - val_loss: 0.2282 - val_accuracy: 0.5960\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9577 - accuracy: 0.5861 - val_loss: 0.2276 - val_accuracy: 0.5969\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9224 - accuracy: 0.5792 - val_loss: 0.2271 - val_accuracy: 0.5984\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7612 - accuracy: 0.6053 - val_loss: 0.2267 - val_accuracy: 0.6048\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8755 - accuracy: 0.5822 - val_loss: 0.2262 - val_accuracy: 0.6088\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8446 - accuracy: 0.5896 - val_loss: 0.2258 - val_accuracy: 0.6068\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8474 - accuracy: 0.5906 - val_loss: 0.2253 - val_accuracy: 0.6107\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8276 - accuracy: 0.6014 - val_loss: 0.2249 - val_accuracy: 0.6132\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7962 - accuracy: 0.5955 - val_loss: 0.2245 - val_accuracy: 0.6191\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7806 - accuracy: 0.6009 - val_loss: 0.2242 - val_accuracy: 0.6220\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7922 - accuracy: 0.6073 - val_loss: 0.2238 - val_accuracy: 0.6275\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7610 - accuracy: 0.6043 - val_loss: 0.2235 - val_accuracy: 0.6289\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7365 - accuracy: 0.6058 - val_loss: 0.2231 - val_accuracy: 0.6319\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6846 - accuracy: 0.6078 - val_loss: 0.2228 - val_accuracy: 0.6319\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6742 - accuracy: 0.6038 - val_loss: 0.2224 - val_accuracy: 0.6329\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7084 - accuracy: 0.6107 - val_loss: 0.2221 - val_accuracy: 0.6324\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6924 - accuracy: 0.5896 - val_loss: 0.2217 - val_accuracy: 0.6324\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6753 - accuracy: 0.5876 - val_loss: 0.2214 - val_accuracy: 0.6339\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6950 - accuracy: 0.5945 - val_loss: 0.2211 - val_accuracy: 0.6358\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6611 - accuracy: 0.6132 - val_loss: 0.2208 - val_accuracy: 0.6373\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6814 - accuracy: 0.6201 - val_loss: 0.2205 - val_accuracy: 0.6388\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6194 - accuracy: 0.6053 - val_loss: 0.2202 - val_accuracy: 0.6432\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6055 - accuracy: 0.6284 - val_loss: 0.2199 - val_accuracy: 0.6452\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6479 - accuracy: 0.6132 - val_loss: 0.2196 - val_accuracy: 0.6476\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5755 - accuracy: 0.6171 - val_loss: 0.2193 - val_accuracy: 0.6550\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6010 - accuracy: 0.6294 - val_loss: 0.2191 - val_accuracy: 0.6614\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5942 - accuracy: 0.6284 - val_loss: 0.2187 - val_accuracy: 0.6673\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5983 - accuracy: 0.6329 - val_loss: 0.2185 - val_accuracy: 0.6673\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5676 - accuracy: 0.6255 - val_loss: 0.2182 - val_accuracy: 0.6708\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5602 - accuracy: 0.6289 - val_loss: 0.2179 - val_accuracy: 0.6786\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5165 - accuracy: 0.6265 - val_loss: 0.2178 - val_accuracy: 0.6816\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5110 - accuracy: 0.6240 - val_loss: 0.2177 - val_accuracy: 0.6870\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5531 - accuracy: 0.6334 - val_loss: 0.2175 - val_accuracy: 0.6870\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5331 - accuracy: 0.6171 - val_loss: 0.2172 - val_accuracy: 0.6909\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4960 - accuracy: 0.6132 - val_loss: 0.2171 - val_accuracy: 0.6895\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4773 - accuracy: 0.6373 - val_loss: 0.2169 - val_accuracy: 0.6929\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4483 - accuracy: 0.6206 - val_loss: 0.2167 - val_accuracy: 0.6939\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4652 - accuracy: 0.6240 - val_loss: 0.2164 - val_accuracy: 0.6924\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.4823 - accuracy: 0.6260 - val_loss: 0.2162 - val_accuracy: 0.6924\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5136 - accuracy: 0.6422 - val_loss: 0.2160 - val_accuracy: 0.6919\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4708 - accuracy: 0.6225 - val_loss: 0.2158 - val_accuracy: 0.6914\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4724 - accuracy: 0.6486 - val_loss: 0.2157 - val_accuracy: 0.6914\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5013 - accuracy: 0.6412 - val_loss: 0.2154 - val_accuracy: 0.6914\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4430 - accuracy: 0.6501 - val_loss: 0.2152 - val_accuracy: 0.6959\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4276 - accuracy: 0.6206 - val_loss: 0.2150 - val_accuracy: 0.6978\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4324 - accuracy: 0.6570 - val_loss: 0.2148 - val_accuracy: 0.6983\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4020 - accuracy: 0.6245 - val_loss: 0.2146 - val_accuracy: 0.6973\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3822 - accuracy: 0.6481 - val_loss: 0.2143 - val_accuracy: 0.6998\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4170 - accuracy: 0.6314 - val_loss: 0.2141 - val_accuracy: 0.7003\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4278 - accuracy: 0.6462 - val_loss: 0.2139 - val_accuracy: 0.7042\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4485 - accuracy: 0.6368 - val_loss: 0.2136 - val_accuracy: 0.7077\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4058 - accuracy: 0.6388 - val_loss: 0.2134 - val_accuracy: 0.7111\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4309 - accuracy: 0.6339 - val_loss: 0.2132 - val_accuracy: 0.7126\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3932 - accuracy: 0.6526 - val_loss: 0.2130 - val_accuracy: 0.7111\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3807 - accuracy: 0.6531 - val_loss: 0.2128 - val_accuracy: 0.7106\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3791 - accuracy: 0.6373 - val_loss: 0.2126 - val_accuracy: 0.7111\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3790 - accuracy: 0.6501 - val_loss: 0.2125 - val_accuracy: 0.7111\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4165 - accuracy: 0.6186 - val_loss: 0.2122 - val_accuracy: 0.7111\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3818 - accuracy: 0.6294 - val_loss: 0.2120 - val_accuracy: 0.7106\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4006 - accuracy: 0.6363 - val_loss: 0.2117 - val_accuracy: 0.7101\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3385 - accuracy: 0.6560 - val_loss: 0.2115 - val_accuracy: 0.7101\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3343 - accuracy: 0.6407 - val_loss: 0.2113 - val_accuracy: 0.7096\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3597 - accuracy: 0.6570 - val_loss: 0.2112 - val_accuracy: 0.7111\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3525 - accuracy: 0.6629 - val_loss: 0.2109 - val_accuracy: 0.7096\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3303 - accuracy: 0.6398 - val_loss: 0.2107 - val_accuracy: 0.7096\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3673 - accuracy: 0.6358 - val_loss: 0.2105 - val_accuracy: 0.7121\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3244 - accuracy: 0.6609 - val_loss: 0.2104 - val_accuracy: 0.7126\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3194 - accuracy: 0.6383 - val_loss: 0.2102 - val_accuracy: 0.7141\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3232 - accuracy: 0.6491 - val_loss: 0.2100 - val_accuracy: 0.7126\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3428 - accuracy: 0.6275 - val_loss: 0.2099 - val_accuracy: 0.7131\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3107 - accuracy: 0.6481 - val_loss: 0.2096 - val_accuracy: 0.7131\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3722 - accuracy: 0.6452 - val_loss: 0.2094 - val_accuracy: 0.7146\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3214 - accuracy: 0.6516 - val_loss: 0.2092 - val_accuracy: 0.7151\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3010 - accuracy: 0.6718 - val_loss: 0.2090 - val_accuracy: 0.7234\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3291 - accuracy: 0.6565 - val_loss: 0.2088 - val_accuracy: 0.7264\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3383 - accuracy: 0.6496 - val_loss: 0.2085 - val_accuracy: 0.7318\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2885 - accuracy: 0.6663 - val_loss: 0.2085 - val_accuracy: 0.7352\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3040 - accuracy: 0.6516 - val_loss: 0.2083 - val_accuracy: 0.7372\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2883 - accuracy: 0.6521 - val_loss: 0.2082 - val_accuracy: 0.7382\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2866 - accuracy: 0.6658 - val_loss: 0.2082 - val_accuracy: 0.7397\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2821 - accuracy: 0.6703 - val_loss: 0.2081 - val_accuracy: 0.7397\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2807 - accuracy: 0.6565 - val_loss: 0.2081 - val_accuracy: 0.7402\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3033 - accuracy: 0.6422 - val_loss: 0.2080 - val_accuracy: 0.7416\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2849 - accuracy: 0.6767 - val_loss: 0.2079 - val_accuracy: 0.7431\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3187 - accuracy: 0.6398 - val_loss: 0.2078 - val_accuracy: 0.7431\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2797 - accuracy: 0.6535 - val_loss: 0.2078 - val_accuracy: 0.7431\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2723 - accuracy: 0.6501 - val_loss: 0.2077 - val_accuracy: 0.7436\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2835 - accuracy: 0.6452 - val_loss: 0.2078 - val_accuracy: 0.7461\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2725 - accuracy: 0.6383 - val_loss: 0.2078 - val_accuracy: 0.7490\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3041 - accuracy: 0.6417 - val_loss: 0.2078 - val_accuracy: 0.7500\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2911 - accuracy: 0.6526 - val_loss: 0.2079 - val_accuracy: 0.7544\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2763 - accuracy: 0.6535 - val_loss: 0.2079 - val_accuracy: 0.7544\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2698 - accuracy: 0.6634 - val_loss: 0.2081 - val_accuracy: 0.7554\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3120 - accuracy: 0.6486 - val_loss: 0.2082 - val_accuracy: 0.7564\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2436 - accuracy: 0.6791 - val_loss: 0.2084 - val_accuracy: 0.7579\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2727 - accuracy: 0.6506 - val_loss: 0.2085 - val_accuracy: 0.7594\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2664 - accuracy: 0.6437 - val_loss: 0.2086 - val_accuracy: 0.7594\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2623 - accuracy: 0.6545 - val_loss: 0.2087 - val_accuracy: 0.7603\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2484 - accuracy: 0.6422 - val_loss: 0.2088 - val_accuracy: 0.7623\n",
      "Epoch 117/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2577 - accuracy: 0.6673 - val_loss: 0.2090 - val_accuracy: 0.7628\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2679 - accuracy: 0.6516 - val_loss: 0.2091 - val_accuracy: 0.7638\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2537 - accuracy: 0.6639 - val_loss: 0.2092 - val_accuracy: 0.7643\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2609 - accuracy: 0.6535 - val_loss: 0.2093 - val_accuracy: 0.7643\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2510 - accuracy: 0.6378 - val_loss: 0.2093 - val_accuracy: 0.7653\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2659 - accuracy: 0.6634 - val_loss: 0.2093 - val_accuracy: 0.7653\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2637 - accuracy: 0.6373 - val_loss: 0.2094 - val_accuracy: 0.7648\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2695 - accuracy: 0.6516 - val_loss: 0.2095 - val_accuracy: 0.7648\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2436 - accuracy: 0.6693 - val_loss: 0.2097 - val_accuracy: 0.7653\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2537 - accuracy: 0.6471 - val_loss: 0.2099 - val_accuracy: 0.7653\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2382 - accuracy: 0.6811 - val_loss: 0.2101 - val_accuracy: 0.7653\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2687 - accuracy: 0.6511 - val_loss: 0.2102 - val_accuracy: 0.7648\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2376 - accuracy: 0.6668 - val_loss: 0.2105 - val_accuracy: 0.7653\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2501 - accuracy: 0.6309 - val_loss: 0.2107 - val_accuracy: 0.7653\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2594 - accuracy: 0.6555 - val_loss: 0.2109 - val_accuracy: 0.7662\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2445 - accuracy: 0.6521 - val_loss: 0.2112 - val_accuracy: 0.7662\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2523 - accuracy: 0.6403 - val_loss: 0.2115 - val_accuracy: 0.7662\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2526 - accuracy: 0.6560 - val_loss: 0.2117 - val_accuracy: 0.7662\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2530 - accuracy: 0.6363 - val_loss: 0.2120 - val_accuracy: 0.7662\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2335 - accuracy: 0.6821 - val_loss: 0.2123 - val_accuracy: 0.7662\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2328 - accuracy: 0.6673 - val_loss: 0.2126 - val_accuracy: 0.7662\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2403 - accuracy: 0.6545 - val_loss: 0.2129 - val_accuracy: 0.7662\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2422 - accuracy: 0.6693 - val_loss: 0.2131 - val_accuracy: 0.7657\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2434 - accuracy: 0.6580 - val_loss: 0.2134 - val_accuracy: 0.7657\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2368 - accuracy: 0.6545 - val_loss: 0.2136 - val_accuracy: 0.7657\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2373 - accuracy: 0.6526 - val_loss: 0.2139 - val_accuracy: 0.7657\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2330 - accuracy: 0.6590 - val_loss: 0.2143 - val_accuracy: 0.7657\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2403 - accuracy: 0.6422 - val_loss: 0.2145 - val_accuracy: 0.7662\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2341 - accuracy: 0.6614 - val_loss: 0.2148 - val_accuracy: 0.7662\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2451 - accuracy: 0.6358 - val_loss: 0.2149 - val_accuracy: 0.7662\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2440 - accuracy: 0.6334 - val_loss: 0.2151 - val_accuracy: 0.7662\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2555 - accuracy: 0.6117 - val_loss: 0.2152 - val_accuracy: 0.7662\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2339 - accuracy: 0.6245 - val_loss: 0.2153 - val_accuracy: 0.7662\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2472 - accuracy: 0.6270 - val_loss: 0.2155 - val_accuracy: 0.7662\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2282 - accuracy: 0.6609 - val_loss: 0.2158 - val_accuracy: 0.7662\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2401 - accuracy: 0.6275 - val_loss: 0.2159 - val_accuracy: 0.7662\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2421 - accuracy: 0.6196 - val_loss: 0.2160 - val_accuracy: 0.7662\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2263 - accuracy: 0.6521 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2653 - accuracy: 0.6186 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2268 - accuracy: 0.6614 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2372 - accuracy: 0.6245 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2377 - accuracy: 0.6245 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2362 - accuracy: 0.6467 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2279 - accuracy: 0.6255 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2378 - accuracy: 0.6127 - val_loss: 0.2161 - val_accuracy: 0.7662\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2335 - accuracy: 0.6590 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2317 - accuracy: 0.6265 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2387 - accuracy: 0.6058 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2274 - accuracy: 0.6363 - val_loss: 0.2163 - val_accuracy: 0.7662\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2417 - accuracy: 0.6127 - val_loss: 0.2163 - val_accuracy: 0.7662\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2324 - accuracy: 0.6112 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2265 - accuracy: 0.6594 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2360 - accuracy: 0.6491 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2301 - accuracy: 0.6353 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2270 - accuracy: 0.6516 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2227 - accuracy: 0.6329 - val_loss: 0.2162 - val_accuracy: 0.7662\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2425 - accuracy: 0.7023 - val_loss: 0.2164 - val_accuracy: 0.7662\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2307 - accuracy: 0.6339 - val_loss: 0.2164 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2292 - accuracy: 0.6560 - val_loss: 0.2165 - val_accuracy: 0.7662\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2277 - accuracy: 0.6658 - val_loss: 0.2165 - val_accuracy: 0.7662\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2299 - accuracy: 0.6870 - val_loss: 0.2167 - val_accuracy: 0.7662\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2310 - accuracy: 0.6457 - val_loss: 0.2168 - val_accuracy: 0.7662\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2350 - accuracy: 0.6639 - val_loss: 0.2169 - val_accuracy: 0.7662\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2257 - accuracy: 0.6471 - val_loss: 0.2170 - val_accuracy: 0.7662\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2220 - accuracy: 0.6211 - val_loss: 0.2170 - val_accuracy: 0.7662\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2321 - accuracy: 0.6265 - val_loss: 0.2171 - val_accuracy: 0.7662\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2198 - accuracy: 0.6314 - val_loss: 0.2171 - val_accuracy: 0.7662\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2232 - accuracy: 0.6329 - val_loss: 0.2172 - val_accuracy: 0.7662\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2341 - accuracy: 0.5866 - val_loss: 0.2172 - val_accuracy: 0.7662\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2227 - accuracy: 0.6407 - val_loss: 0.2173 - val_accuracy: 0.7662\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2184 - accuracy: 0.6220 - val_loss: 0.2173 - val_accuracy: 0.7662\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2425 - accuracy: 0.6575 - val_loss: 0.2175 - val_accuracy: 0.7662\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2327 - accuracy: 0.6009 - val_loss: 0.2175 - val_accuracy: 0.7662\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2267 - accuracy: 0.6339 - val_loss: 0.2175 - val_accuracy: 0.7662\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2249 - accuracy: 0.6339 - val_loss: 0.2176 - val_accuracy: 0.7662\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2316 - accuracy: 0.6265 - val_loss: 0.2177 - val_accuracy: 0.7662\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2266 - accuracy: 0.6265 - val_loss: 0.2177 - val_accuracy: 0.7662\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2368 - accuracy: 0.6757 - val_loss: 0.2179 - val_accuracy: 0.7662\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2231 - accuracy: 0.6033 - val_loss: 0.2180 - val_accuracy: 0.7662\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2261 - accuracy: 0.6457 - val_loss: 0.2181 - val_accuracy: 0.7662\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2442 - accuracy: 0.5832 - val_loss: 0.2180 - val_accuracy: 0.7662\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2332 - accuracy: 0.6107 - val_loss: 0.2180 - val_accuracy: 0.7662\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2284 - accuracy: 0.6344 - val_loss: 0.2182 - val_accuracy: 0.7662\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2360 - accuracy: 0.5743 - val_loss: 0.2182 - val_accuracy: 0.7662\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2257 - accuracy: 0.6412 - val_loss: 0.2184 - val_accuracy: 0.7662\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2224 - accuracy: 0.6250 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2367 - accuracy: 0.6289 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2285 - accuracy: 0.6314 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2227 - accuracy: 0.6373 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2239 - accuracy: 0.6216 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2303 - accuracy: 0.6122 - val_loss: 0.2186 - val_accuracy: 0.7662\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2295 - accuracy: 0.5856 - val_loss: 0.2186 - val_accuracy: 0.7662\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2291 - accuracy: 0.6097 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2268 - accuracy: 0.5915 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2312 - accuracy: 0.5979 - val_loss: 0.2186 - val_accuracy: 0.7662\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2298 - accuracy: 0.5965 - val_loss: 0.2185 - val_accuracy: 0.7662\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2293 - accuracy: 0.6565 - val_loss: 0.2187 - val_accuracy: 0.7662\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2313 - accuracy: 0.5925 - val_loss: 0.2187 - val_accuracy: 0.7662\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2209 - accuracy: 0.6363 - val_loss: 0.2188 - val_accuracy: 0.7662\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2212 - accuracy: 0.6796 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2244 - accuracy: 0.5945 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 218/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2257 - accuracy: 0.5822 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2237 - accuracy: 0.6329 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2242 - accuracy: 0.6176 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2280 - accuracy: 0.5989 - val_loss: 0.2188 - val_accuracy: 0.7662\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.64 - 0s 40ms/step - loss: 0.2192 - accuracy: 0.6442 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2254 - accuracy: 0.6078 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2230 - accuracy: 0.6535 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2242 - accuracy: 0.6024 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2215 - accuracy: 0.6112 - val_loss: 0.2188 - val_accuracy: 0.7662\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2213 - accuracy: 0.5920 - val_loss: 0.2188 - val_accuracy: 0.7662\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2296 - accuracy: 0.6688 - val_loss: 0.2189 - val_accuracy: 0.7662\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2259 - accuracy: 0.6363 - val_loss: 0.2190 - val_accuracy: 0.7662\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2191 - accuracy: 0.6353 - val_loss: 0.2190 - val_accuracy: 0.7662\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2236 - accuracy: 0.6206 - val_loss: 0.2191 - val_accuracy: 0.7662\n",
      "Epoch 232/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2192 - accuracy: 0.6403 - val_loss: 0.2191 - val_accuracy: 0.7662\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2220 - accuracy: 0.6048 - val_loss: 0.2191 - val_accuracy: 0.7662\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2265 - accuracy: 0.6225 - val_loss: 0.2193 - val_accuracy: 0.7662\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2222 - accuracy: 0.6511 - val_loss: 0.2193 - val_accuracy: 0.7662\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2238 - accuracy: 0.6038 - val_loss: 0.2193 - val_accuracy: 0.7662\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2270 - accuracy: 0.5960 - val_loss: 0.2193 - val_accuracy: 0.7662\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2193 - accuracy: 0.6457 - val_loss: 0.2194 - val_accuracy: 0.7662\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2209 - accuracy: 0.6211 - val_loss: 0.2194 - val_accuracy: 0.7662\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2277 - accuracy: 0.6447 - val_loss: 0.2196 - val_accuracy: 0.7662\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2255 - accuracy: 0.5989 - val_loss: 0.2195 - val_accuracy: 0.7662\n",
      "Epoch 242/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2271 - accuracy: 0.6024 - val_loss: 0.2195 - val_accuracy: 0.7662\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2237 - accuracy: 0.6786 - val_loss: 0.2196 - val_accuracy: 0.7662\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2207 - accuracy: 0.6127 - val_loss: 0.2197 - val_accuracy: 0.7662\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2284 - accuracy: 0.5969 - val_loss: 0.2197 - val_accuracy: 0.7662\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2276 - accuracy: 0.6127 - val_loss: 0.2196 - val_accuracy: 0.7662\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2184 - accuracy: 0.6280 - val_loss: 0.2197 - val_accuracy: 0.7662\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2251 - accuracy: 0.6348 - val_loss: 0.2198 - val_accuracy: 0.7662\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2349 - accuracy: 0.6038 - val_loss: 0.2197 - val_accuracy: 0.7662\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2355 - accuracy: 0.6865 - val_loss: 0.2200 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1be41b95d60>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcn_model = TCN(filters, kernel_size, activation='relu', trainable = True, dtype='float')\n",
    "tcn_model.compile(optimizer='adam', loss = 'mse', metrics=['accuracy'])\n",
    "tcn_model.fit(stock_training_input, stock_training_output, epochs = 250, validation_data=(stock_validation_input, stock_validation_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1be41baa0d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(tcn_model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
