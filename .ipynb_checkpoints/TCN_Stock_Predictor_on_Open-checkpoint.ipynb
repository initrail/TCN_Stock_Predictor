{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Layer, Conv1D, Dropout, Dense, Activation, BatchNormalization, Input, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import pandas as pd\n",
    "from pandas_datareader import DataReader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import seaborn as sns\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL', 'TSLA', 'NVDA', 'MSFT', 'GOOGL', 'F']\n",
    "start = '10-10-2018'\n",
    "end = '10-10-2020'\n",
    "api = 'yahoo'\n",
    "stocks = {}\n",
    "for symbol in symbols:\n",
    "    stocks[symbol] = DataReader(symbol, api, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in stocks:\n",
    "    data = stocks[symbol]\n",
    "    data['Buy'] = data['Close'] > data['Open']\n",
    "    data['Buy'] = data['Buy'].astype(int)\n",
    "    data['Sell'] = data['Close'] < data['Open']\n",
    "    data['Sell'] = data['Sell'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldf = 8 #largest dilation factor\n",
    "feature_count = 100 #get 30 unique features\n",
    "final_output = 1 #only one output feature, a number in the range of [0-1] with 1 meaning hold/buy and 0 meaning (don't buy)/sell\n",
    "feature_window = 10 #how big the window is for each feature\n",
    "train_split = feature_window+(feature_window-1)*(ldf-1) #calculate the receptive field of the TCN\n",
    "features = [feature_count]*(int(math.log(ldf)/math.log(2)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "train_x = []\n",
    "valid_x = []\n",
    "valid_y = []\n",
    "for symbol in stocks:\n",
    "    data = stocks[symbol]\n",
    "    outdata = data[['Buy', 'Sell']].values\n",
    "    \n",
    "    indata = data[['Volume']].copy()\n",
    "    indata['Day Avg'] = data[['Open', 'High', 'Low']].mean(axis=1)\n",
    "    indata = scaler.fit_transform(indata.values)\n",
    "    opendata = indata[:,1]\n",
    "    \n",
    "    train_y.append(outdata[:train_split].reshape((1, train_split, 2)))\n",
    "    valid_y.append(outdata[train_split:2*train_split].reshape((1, train_split, 2)))\n",
    "    \n",
    "    train_x.append(opendata[:train_split].reshape((1, train_split, 1)))\n",
    "    valid_x.append(opendata[train_split:2*train_split].reshape((1, train_split, 1)))\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "valid_x = np.array(valid_x)\n",
    "valid_y = np.array(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 73, 2)\n",
      "(6, 1, 73, 2)\n",
      "(6, 1, 73, 1)\n",
      "(6, 1, 73, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(valid_y.shape)\n",
    "print(train_x.shape)\n",
    "print(valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN(Model):\n",
    "    def __init__(self, features, kernel_size, dropout=0.2, activation='relu'):\n",
    "        super(TCN, self).__init__()\n",
    "        self.convs1 = []\n",
    "        self.convs2 = []\n",
    "        self.features = features\n",
    "        self.levels = len(features)\n",
    "        for i in range(self.levels):\n",
    "            self.convs1.append(Conv1D(features[i], kernel_size, 1, 'causal', dilation_rate=2**i))\n",
    "            self.convs2.append(Conv1D(features[i], kernel_size, 1, 'causal', dilation_rate=2**i))\n",
    "        self.maxp = MaxPooling1D(features[0], strides = features[0], padding='same')\n",
    "        self.maxp2 = MaxPooling1D(int(features[0]/2), strides = int(features[0]/2), padding = 'same')\n",
    "        self.batch_norm = BatchNormalization(1)\n",
    "        self.activation = Activation(activation)\n",
    "        self.finalactivation = Activation('softmax')\n",
    "        self.drop = Dropout(dropout, (1, train_split, 1))\n",
    "    def call(self, inputs, training = False):\n",
    "        length = inputs.shape[1]\n",
    "        for i in range(self.levels):\n",
    "            x = self.convs1[i](inputs)\n",
    "            x = tf.reshape(x, (1, length*features[i], 1))\n",
    "            x = self.maxp(x)\n",
    "            x = self.batch_norm(x, training)\n",
    "            x = self.activation(x)\n",
    "            x = self.drop(x, training)\n",
    "\n",
    "            x = self.convs2[i](x)\n",
    "            x = tf.reshape(x, (1, length*features[i], 1))\n",
    "            if i == self.levels-1:\n",
    "                x = self.maxp2(x)\n",
    "                x = tf.reshape(x, (1, train_split, 2))\n",
    "                x = self.batch_norm(x, training)\n",
    "                inputs = self.finalactivation(x + inputs)\n",
    "            else:\n",
    "                x = self.maxp(x)\n",
    "                x = self.batch_norm(x, training)\n",
    "                x = self.activation(x)\n",
    "                x = self.drop(x, training)\n",
    "                inputs = self.activation(x + inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 0.7006 - accuracy: 0.5205 - val_loss: 0.6932 - val_accuracy: 0.4932\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.7168 - accuracy: 0.4932 - val_loss: 0.6930 - val_accuracy: 0.5205\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6984 - accuracy: 0.5068 - val_loss: 0.6932 - val_accuracy: 0.4658\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7259 - accuracy: 0.4932 - val_loss: 0.6934 - val_accuracy: 0.4658\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6949 - accuracy: 0.5205 - val_loss: 0.6935 - val_accuracy: 0.4658\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.7042 - accuracy: 0.4795 - val_loss: 0.6934 - val_accuracy: 0.4932\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6972 - accuracy: 0.4932 - val_loss: 0.6935 - val_accuracy: 0.4932\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6858 - accuracy: 0.5616 - val_loss: 0.6935 - val_accuracy: 0.4658\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6681 - accuracy: 0.6438 - val_loss: 0.6937 - val_accuracy: 0.4658\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6942 - accuracy: 0.5342 - val_loss: 0.6939 - val_accuracy: 0.4658\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7012 - accuracy: 0.5479 - val_loss: 0.6938 - val_accuracy: 0.4658\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6804 - accuracy: 0.5890 - val_loss: 0.6940 - val_accuracy: 0.4658\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6733 - accuracy: 0.4932 - val_loss: 0.6940 - val_accuracy: 0.4658\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6865 - accuracy: 0.5479 - val_loss: 0.6940 - val_accuracy: 0.4658\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6970 - accuracy: 0.5753 - val_loss: 0.6939 - val_accuracy: 0.4658\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6929 - accuracy: 0.4932 - val_loss: 0.6941 - val_accuracy: 0.4658\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6819 - accuracy: 0.4795 - val_loss: 0.6943 - val_accuracy: 0.4384\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6885 - accuracy: 0.5616 - val_loss: 0.6940 - val_accuracy: 0.4384\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7156 - accuracy: 0.4384 - val_loss: 0.6943 - val_accuracy: 0.4384\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6975 - accuracy: 0.4658 - val_loss: 0.6942 - val_accuracy: 0.4384\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6706 - accuracy: 0.5479 - val_loss: 0.6944 - val_accuracy: 0.4384\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6813 - accuracy: 0.5068 - val_loss: 0.6943 - val_accuracy: 0.4384\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6936 - accuracy: 0.5479 - val_loss: 0.6943 - val_accuracy: 0.4384\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6865 - accuracy: 0.5342 - val_loss: 0.6942 - val_accuracy: 0.4658\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6920 - accuracy: 0.5616 - val_loss: 0.6942 - val_accuracy: 0.4932\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7138 - accuracy: 0.4795 - val_loss: 0.6945 - val_accuracy: 0.4658\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6841 - accuracy: 0.5753 - val_loss: 0.6948 - val_accuracy: 0.4384\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7298 - accuracy: 0.4247 - val_loss: 0.6949 - val_accuracy: 0.4384\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6722 - accuracy: 0.5479 - val_loss: 0.6947 - val_accuracy: 0.5205\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6732 - accuracy: 0.6164 - val_loss: 0.6949 - val_accuracy: 0.4658\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6848 - accuracy: 0.5753 - val_loss: 0.6944 - val_accuracy: 0.4658\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6978 - accuracy: 0.5616 - val_loss: 0.6952 - val_accuracy: 0.4658\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6811 - accuracy: 0.5890 - val_loss: 0.6954 - val_accuracy: 0.4658\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6979 - accuracy: 0.5068 - val_loss: 0.6953 - val_accuracy: 0.4658\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7009 - accuracy: 0.5479 - val_loss: 0.6959 - val_accuracy: 0.4521\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6871 - accuracy: 0.5068 - val_loss: 0.6959 - val_accuracy: 0.4384\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6682 - accuracy: 0.6164 - val_loss: 0.6958 - val_accuracy: 0.4932\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6786 - accuracy: 0.5890 - val_loss: 0.6965 - val_accuracy: 0.4384\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6813 - accuracy: 0.5616 - val_loss: 0.6971 - val_accuracy: 0.4384\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6788 - accuracy: 0.5753 - val_loss: 0.6979 - val_accuracy: 0.4384\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6642 - accuracy: 0.6164 - val_loss: 0.6980 - val_accuracy: 0.4384\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6663 - accuracy: 0.5890 - val_loss: 0.6975 - val_accuracy: 0.4384\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6462 - accuracy: 0.6849 - val_loss: 0.6987 - val_accuracy: 0.4384\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6825 - accuracy: 0.5890 - val_loss: 0.6985 - val_accuracy: 0.4384\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6857 - accuracy: 0.5753 - val_loss: 0.6989 - val_accuracy: 0.4384\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6736 - accuracy: 0.6027 - val_loss: 0.6998 - val_accuracy: 0.4384\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7084 - accuracy: 0.5205 - val_loss: 0.7011 - val_accuracy: 0.4384\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6734 - accuracy: 0.6027 - val_loss: 0.7004 - val_accuracy: 0.4384\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6653 - accuracy: 0.5616 - val_loss: 0.7004 - val_accuracy: 0.4384\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6828 - accuracy: 0.6027 - val_loss: 0.6999 - val_accuracy: 0.4384\n"
     ]
    }
   ],
   "source": [
    "model = TCN(features, feature_window, 0.4, 'sigmoid')\n",
    "model.compile(optimizer = 'rmsprop', loss=CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "for i in range(1):\n",
    "    model.fit(x=train_x[i], y=train_y[i], epochs=50, validation_data=(valid_x[i], valid_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022260A46AF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]]]\n",
      "[[[0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [1 0]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [0 1]\n",
      "  [1 0]\n",
      "  [1 0]]]\n"
     ]
    }
   ],
   "source": [
    "out = model.predict(train_x[1])\n",
    "for i in range(out.shape[1]):\n",
    "    if out[0, i, 0] > .5:\n",
    "        if i == 0:\n",
    "            print('[[[1 0]')\n",
    "        elif i == out.shape[1] - 1:\n",
    "            print('  [1 0]]]')\n",
    "        else:\n",
    "            print('  [1 0]')\n",
    "    else:\n",
    "        if i == 0:\n",
    "            print('[[[0 1]')\n",
    "        elif i == out.shape[1] -1:\n",
    "            print('  [0 1]]]')\n",
    "        else:\n",
    "            print('  [0 1]')\n",
    "print(train_y[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
